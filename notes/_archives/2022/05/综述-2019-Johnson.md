综述-2019-Johnson
===
<!--START_SECTION:badge-->

![create date](https://img.shields.io/static/v1?label=create%20date&message=2022-05-xx&label_color=gray&color=lightsteelblue&style=flat-square)
![last modify](https://img.shields.io/static/v1?label=last%20modify&message=2025-08-03%2022%3A42%3A16&label_color=gray&color=thistle&style=flat-square)

<!--END_SECTION:badge-->
<!--info
top: false
draft: false
hidden: false
tag: [dl_unbalanced]
-->

> ***Keywords**: 综述-2019-Johnson*

<!--START_SECTION:toc-->
- [概述](#概述)
    - [评价指标](#评价指标)
    - [机器学习中的一般方法](#机器学习中的一般方法)
- [深度学习中常见的解决方法](#深度学习中常见的解决方法)
    - [数据层](#数据层)
        - [ROS (上采样) ](#ros上采样)
        - [Two‑phase learning (两阶段学习) ](#twophase-learning两阶段学习)
        - [Dynamic sampling (动态采样) ](#dynamic-sampling动态采样)
        - [ROS, RUS, and two‑phase learning](#ros-rus-and-twophase-learning)
    - [算法层](#算法层)
        - [Mean Squared False Error (MFE) loss](#mean-squared-false-error-mfe-loss)
        - [Focal Loss](#focal-loss)
        - [Cost‑sensitive deep neural network (CSDNN)](#costsensitive-deep-neural-network-csdnn)
- [参考资料](#参考资料)
<!--END_SECTION:toc-->

---
> 介绍了目前在深度学习中常用的不平衡学习方法, 主要包括从数据角度和算法角度提出的方法;

## 概述

- 数据不平衡的影响会随着问题复杂度的增加而增加; 简单的线性可分问题不会受到数据不平衡的影响;
- 一个简单衡量数据集不平衡率的指标:
    $$\rho = \frac{\max_i\{|C_i|\}}{\min_i\{|C_i|\}}$$
    比如最大类别的样本数为 100, 最小的为 10, 则 $\rho = 10$;
- 需要注意的是, 有时少数类别样本的绝对值比占比更重要; 比如在一个包含 100 万样本的数据集中, 即使某个类别只占 1%, 也有 1 万条样本可供学习;
- 一些研究将不平衡问题看做是**对困难样本的学习**问题; 在大多数场景下, 可以认为两者的目标是一致的;

### 评价指标

- 在处理不平衡问题时, 只使用准确率或错误率是不够的; 此时占主导的是多数类别的样本;
- 常用指标计算公式
    - **混淆矩阵**
        | \                  | Actual positive     | Actual negative     |
        | ------------------ | ------------------- | ------------------- |
        | Predicted positive | True positive (TP)  | False positive (FP) |
        | Predicted negative | False negative (FN) | True negative (TN)  |
    - **Accuracy (准确率) **
        $$Accuracy = \frac{TP + TN}{TP + TN + FP + FN}$$
    - **Error Rate (错误率) **
        $$Error Rate = 1 − Accuracy$$
    - **Precision (精确率) **
        $$Precision = \frac{TP}{TP + FP}$$
    - **Recall (召回率) 或 TPR (True Positive Rate, 真阳率) **
        $$Recall = TPR = \frac{TP}{TP + FN}$$
    - **Selectivity 或 TNR (True Negative Rate, 真阴率) **
        $$Selectivity = TNR = \frac{TN}{TN + FP}$$
    - **F-Measure**
        $$F_\beta=(1+\beta^2)\times \frac{Precision \times Recall}{(\beta^2 \times Precision) + Recall}$$
        $$F_1 = 2 \times \frac{Precision \times Recall}{Precision + Recall}$$
    - **G-Mean**
        $$G\text{-}Mean = \sqrt{TPR * TRN}$$
    - **Balanced Accuracy**
        $$Balanced Accuracy = \frac{1}{2} \times (TPR + TRN)$$
- TODO: 精读各指标的作用


### 机器学习中的一般方法

**数据层**
- 随机**下采样/欠采样** (Random Under-Sampling, RUS) : 减少多数群体样本
    - 目标: 保留有价值的信息 (去除冗余的多数群体样本)
    - 常见方法:
        - 利用 K-NN (最近邻) 选择需要丢弃的多数群体样本;
- 随机**上采样/过采样** (Random Over-Sampling, ROS) : 增加少数群体样本
    - 目标: 较少过拟合
    - 常见方法:
        - 利用插值生成新样本;
        - 先对样本进行 K-Means 聚类, 再上采样;
- 相关工具: [scikit-learn-contrib/imbalanced-learn: A Python Package to Tackle the Curse of Imbalanced Datasets in Machine Learning](https://github.com/scikit-learn-contrib/imbalanced-learn)
- **一般结论**:
    - 下采样 (RUS) 效果普遍优于上采样 (ROS) ;
    - 采样效果高度依赖于学习器和评估指标, 没有通用有效的采样方案;

**算法层**
- 相比从数据入手的方法, 算法侧的方法**不会改变数据的分布**;
- 基本策略: 通过调整不同类别的惩罚权重, 从而减少样本偏置;
- 成本矩阵 (Cost Matrix)

<!--
**混合方法**
- 集成学习
 -->


## 深度学习中常见的解决方法

- 对浅层网络, 有研究表明, 在类别不平衡的场景下, 少数类的梯度分量会远小于多数类的梯度分量; 其结果就是训练过程中模型会快速降低多数类的误差, 且通常会导致少数类的误差增加;
- 下面总结了目前深度学习中常见的、用于解决类别不平衡问题的方法, 包括数据层面、算法层面和混合方法;
    - 对每种方法, 讨论了该方法的**实现细节**, 以及用于评估该方法的**数据集特征**;
    - 随后讨论了不同方法的优缺点, 比如: 类别不平衡的程度、结果的可解释性、相对性能、使用并推广到其他结构和问题的难度;


### 数据层
- 主要还是基于**下采样** (RUS) 和**上采样** (ROS) ;

#### ROS (上采样)
> 相关论文: The Impact of Imbalanced Training Data for Convolutional Neural Networks

- **数据集**
    - 基于 CIFAR-10 人工生成的 10 个数据集;
    - 最大 $\rho=2.3$;
- **做法**
    - 通过上采样 (随机复制数据) 使类别达到平衡;
- 本文的研究相对较早 (2015) , 主要讨论了不平衡数据对深度学习模型的影响, 在方法上没有更多创新;

#### Two‑phase learning (两阶段学习)
> 相关论文: Plankton classification on imbalanced large scale database via convolutional neural networks with transfer learning
- **数据集**
    - 数据来源: WHOI-Plankton
    - 103 个类别, 340 万张图片;
    - $\rho > 650$, 数量最多的前 5 个类别占 90%, 第 5 大的类别仅占 1.3%, 其他大多数类别都小于 0.1%;
- **实现细节**
    - 两阶段训练过程:
        - 一阶段: 使用**阈值数据** (thresholded data) 预训练;
            > 阈值数据: 每个类别最多随机采样 N 个样本 (论文中 N = 5000) ;
        - 二阶段: 使用全部数据微调;
- **有效性解释**:
    - 朴素的 RUS 方法直接丢弃多数类样本, 这些被丢弃的样本不再参与到训练中, 而这些样本可能是潜在有用的样本;
    - 两阶段训练方法, 只在预训练阶段丢弃多数类样本, 这保证了少数类样本这此时能得到更大的权重; 同时在微调阶段允许模型观察到全部训练样本;
- **一些优化点**:
    - 作者没有提供预训练阶段更多信息, 比如预训练的 epoch、预训练结束标准等; 这些信息是重要的, 因为预训练模型的状态 (高偏差或高方差) 必然会影响最终的结果;
    - 目前在预训练阶段只对多数类进行下采样, 由于少数类的数据非常少, 限制了 N 的大小, 一个改进方法是同时加入对少数类的上采样结果, 这样就可以进一步提高阈值 N 的大小;


#### Dynamic sampling (动态采样)
> 相关论文: Dynamic sampling in convolutional neural networks for imbalanced data classification

- **数据集**
    - 数据来源: 作者自己收集的
    - 19 个类别, 10000+ 图像;
    - $\rho = 500$;
    - 评价指标: Average F1、Weighted average F1
- **实现细节**
    - 实时数据增强: 就是目前 CV 中的常规做法, 在输入层对图片做变换后再 forward;
    - 迁移学习: 基于预训练好的 Inception-V3 模型微调;
    - 动态采样:
        $$SampleSize(F_i,c_j) = \frac{1-f_{i,j}}{\sum_{c_k\in C}(1-f_{i,k})} \times N^*$$
        - 上式用于生成下一轮训练中各类别采样的数量;
        - $F_i$ 是一个向量, 由每个类在第 $i$ 轮迭代后的 F1 分数组成;
        - $f_{i,j}$ 表示类别 $j$ 在第 $i$ 轮迭代后的 F1 分数;
        - $c_j$ 表示类别 $j$;
        - $N^*$ 表示类别的平均数量, 即样本总数除以类别数;
        - 在下一轮迭代中, F1 较低的类别会以更高的比率被采样, 以迫使学习器更多关注错误率较高的类别;
        - **模型融合** (Model Fusion) : 在训练集上根据**是否使用动态采样**, 训练两个模型; 然后根据验证集上类别的正负比例设定一个阈值, 根据阈值选择其中某个模型的结果, 详见论文;
            > **动机**: 原文认为使用动态采样训练得到的模型会在少数类上的效果更好, 而不使用动态采样的模型会在多数类上效果更好, 因此采用融合的方案; 但是这里阈值的计算方法没有看懂;
- **有效性解释**:
    - 自适应调整采样率本质上就是在通过样本量调整类别权重;
    - 在每一轮训练中, 由于高指标的类别数量少, 低指标的类别数量多, 将迫使模型将更多的学习权重放在低指标的数据上;
    - 因此该方法不仅适用于类别不平衡的问题, 对于均衡但类别学习难度不同的数据集也有用;
- **一些优化点**:
    - 论文没有给出对比方法中具体的上采样和下采样细节, 导致不能确定动态采样的方法是否能完全取代 ROS 和 RUS;
    - 该方法依赖于验证集的构建, 对验证集的数据分布要求较高;
    - 可以尝试拓展到 CV 外的其他领域;


#### ROS, RUS, and two‑phase learning
> 相关论文: A systematic study of the class imbalance problem in convolutional neural networks.

- 本文比较了 7 种基于 ROS、RUS 和两阶段训练的方法;
    - 少数类上采样
    - 多数类下采样
    - 基于随机上采样的二阶段训练
    - 基于随机下采样的二阶段训练
    - 阈值法
    - 上采样+阈值法
    - 下采样+阈值法


### 算法层

- 主要思路:
    - 损失函数: 促使少数类对损失做出更大的贡献;
    - 代价敏感学习 (cost-sensitive learning)
    - 阈值移动 (threshold moving)

#### Mean Squared False Error (MFE) loss
> 相关论文: Training deep neural networks on imbalanced data sets

- **数据集**
    - 基于 CIFAR-100 (图像) 和 20 Newsgroup (文本) 人工构建的不平衡数据集;
    - 数据量: 2000 - 3500 之间;
    - $\rho$ 在 5 到 20 之间;
- **背景&动机**
    - 均方误差损失 (MSE Loss) 很难在不平衡条件下捕捉到少数类群体的误差, 此时多数类主导了损失函数;
    - 受到混淆矩阵的启发, 提出 Mean False Error(MFE) Loss 和 Mean Squared False Error(MSFE) Loss, 通过分别计算不同类别的 MSE Loss, 来平衡少数类和多数类的误差;
- **方法**
    $$MFE = FPE + FNE$$
    $$MSFE = \frac{1}{2}((FPE + FNE)^2 + (FPE - FNE)^2) = FPE^2 + FNE^2$$
    - 其中 $FPE$ 为**假阳误差** (False Positive Error) , $FNE$ 为**假阴误差** (False Negative Error) , 两者均为 MSE Loss;
- **存在问题**
    - 无论是 MFE Loss 还是 MSFE Loss, 都是基于 MSE Loss, 但是在分类问题上使用 MSE 损失的效果并不好;
        > [机器学习理论—损失函数 (二) : MSE、0-1 Loss与Logistic Loss - 知乎](https://zhuanlan.zhihu.com/p/346935187)
- **改进**
    - 可以考虑把基础损失替换成交叉熵;

#### Focal Loss
> 相关论文: Focal loss for dense object detection

- **数据集**
    - 目标检测;
    - $\rho = 1000$, 极端不平衡;
- **背景**
    - 希望提升 One-stage (如 SSD、YOLO) 方法的效果, 达到 Two-stage (如 R-CNN) 的水平;
        > [目标检测专题(一) One-Stage方法 - 知乎](https://zhuanlan.zhihu.com/p/107780772)  
        > [目标检测专题(二) Two-Stage方法 - 知乎](https://zhuanlan.zhihu.com/p/107852736)
    - 分析认为不平衡问题是阻碍 One-stage 方法效果的主要原因;
    - 基于交叉熵, 提出 Focal Loss 降低容易分类的样本对损失的影响;
- **方法**
    - 交叉熵
        $$CELoss = -\log(p_t)$$
    - Focal Loss
        $$Focal Loss= -\alpha_t(1-p_t)^\gamma\log(p_t)$$
    - Focal Loss 在交叉熵的基础上加入了**调制系数** $\alpha_t(1-p_t)^\gamma$
    - 其中 $\gamma$ (> 0) 为超参数, 用于调整简单样本的权重的下降率; $\alpha_t$ 为类别权重用于提升少数类的重要性; 论文中取 $\gamma=2, \alpha=0.25$
    - 简单解释: 对于**易分类**的样本, 当其概率 $p_t$ 接近 1, 此时调制系数将趋向于 0, 进而降低其对 loss 的影响;
- 相关分析
    - [从loss的硬截断、软化到focal loss - 科学空间|Scientific Spaces](https://kexue.fm/archives/4733)


#### Cost‑sensitive deep neural network (CSDNN)
> 相关论文


## 参考资料
- [Survey on deep learning with class imbalance | Journal of Big Data | Full Text](https://journalofbigdata.springeropen.com/articles/10.1186/s40537-019-0192-5)
