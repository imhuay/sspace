不平衡学习概述
===
<!--START_SECTION:badge-->

![create date](https://img.shields.io/static/v1?label=create%20date&message=2022-05-xx&label_color=gray&color=lightsteelblue&style=flat-square)
![last modify](https://img.shields.io/static/v1?label=last%20modify&message=2025-08-03%2022%3A42%3A16&label_color=gray&color=thistle&style=flat-square)

<!--END_SECTION:badge-->
<!--info
top: false
draft: true
hidden: true
tag: [dl_unbalanced]
level: 99
-->

> ***Keywords**: 不平衡学习概述*

<!--START_SECTION:toc-->
- [不平衡问题简述](#不平衡问题简述)
- [基本方法](#基本方法)
    - [数据层面](#数据层面)
    - [算法层面](#算法层面)
<!--END_SECTION:toc-->

---


## 不平衡问题简述

- 不平衡问题的本质是不同类别的**学习难易程度**不同, 造成这个问题的原因是多样的;
- 最常见的一种原因是由于不同类别的训练样本**在数量上存在差异**.
    - 一般来说, 某类别下的训练样本数量越多, 该类别的学习效果就越好; 这个问题一般可以在**训练前**就观察到;
    - 基于这个原因, 一类方法 (从**数据层面**) 通过**调整不同类别的训练样本在数量上的分布**来缓解学习不平衡的问题, 如**上采样**、**下采样**, 及其改进方法;
    - 一个描述训练数据不平衡程度的参考指标:
        $$\rho = \frac{\max_i\{|C_i|\}}{\min_i\{|C_i|\}}$$
        > 其中 $|C_i|$ 表示 $i$ 类别样本的数量, 比如最大类别的样本数为 100, 最小的为 10, 则 $\rho=10$;
- 另一方面, 即使是在样本数量均衡的数据上训练也可能发生不平衡问题;
    - 造成这个现象的原因是因为学习器假设了**不同样本对模型的贡献是相同的**. 但训练数据中可能存在**低质量样本**和**困难样本**等, 这些样本显然不能一视同仁; 而且这些问题**在训练之前观察不到**, 需要在验证集上才能发现 (通过混淆矩阵);
    - 因此另一类方法 (在**算法层面**) 通过**调整不同类别样本的学习权重**来解决这个问题. 这类方法的适用性更广, 因为它在尝试从根源上解决不平衡问题; 调整数据分布的方法本质上也是在调整学习权重, 它的问题是忽略了样本自身的质量;


## 基本方法

### 数据层面

- 上采样 (过采样, Over-Sampling)
- 下采样 (欠采样, Under-Sampling)
- 两阶段学习 (Two‑phase learning)
- 动态采样 (Dynamic Sampling)


### 算法层面

- 阈值移动 (Threshold Moving)
- 代价敏感学习 (Cost Sensitive Learning)
- 通过修改 Loss
    - Focal Loss
- 基于聚类的方法
    - Category Centers
- 异常点检测 (Outlier Detection)

