KDD 2022
===
<!--START_SECTION:badge-->
![create date](https://img.shields.io/static/v1?label=create%20date&message=2022-06-xx&label_color=gray&color=lightsteelblue&style=flat-square)
![last modify](https://img.shields.io/static/v1?label=last%20modify&message=2025-08-03%2022%3A42%3A16&label_color=gray&color=thistle&style=flat-square)
<!--END_SECTION:badge-->
<!--info
top: false
draft: true
hidden: true
level: 0
tags: []
-->

> ***Keywords**: KDD2022*

<!--START_SECTION:paper_title-->
<!--END_SECTION:paper_title-->

<!--START_SECTION:toc-->
- [Workshops](#workshops)
- [论文](#论文)
<!--END_SECTION:toc-->

---

## Workshops

- 表示学习、不平衡学习: Deep learning practice and theory for high-dimensional, sparse, and imbalanced data
- 知识图谱: International Workshop on Knowledge Graphs: Open Knowledge Network
- 时间序列: Workshop on Mining and Learning from Time Series -- Deep Forecasting: Models, Interpretability, and Applications

## 论文
- Mask and Reason: Pre-Training Knowledge Graph Transformers for Complex Logical Queries
    - 知识图谱; KGTransformer;
    - 面向复杂逻辑查询的知识图谱Transformer预训练.
- AutoFAS: Automatic Feature and Architecture Selection for Pre-Ranking System
    - 搜索; 粗排; 双塔模型优化; 神经网络框架搜索(Neural Architecture Search)
- Practical Counterfactual Policy Learning for Top-K Recommendations
    - 数据优化;
    - 问题: 对于训练机器学习模型, 一项关键任务是通过收集的反馈 (例如, 评分、点击) 来构建训练数据. 然而, 从理论和实际经验中可以发现, 收集的反馈中选择偏差会导致训练得到的模型有偏, 从而导致训练结果是不是最优策略.
- Applying Deep Learning Based Probabilistic Forecasting to Food Preparation Time for On-Demand Delivery Service
    - 配送时间预测;
    - 应用概率估计刻画订单出餐时间的不确定性 (区别于点估计); 提出了S-QL损失函数 (基于S-CRPS)
- A Framework for Multi-stage Bonus Allocation in meal delivery Platform
    - 应用; 物流配送相关;
    - 多阶段送餐奖励框架; 优化无人接单问题;
- DDEN:A Heterogeneous Learning-to-Rank Approach with Deep Debiasing Experts Network
    - 应用; 异构排序;
