2015.wsdm.el
===
<!--START_SECTION:badge-->

![last modify](https://img.shields.io/static/v1?label=last%20modify&message=2025-07-25%2002%3A00%3A05&color=yellowgreen&style=flat-square)

<!--END_SECTION:badge-->
<!--info
top: false
hidden: true
-->

> ***Keywords**: 短文本实体链接*

> [Fast and Space-Efficient Entity Linking for Queries | WSDM 2015](https://dl.acm.org/doi/abs/10.1145/2684822.2685317)

<!--START_SECTION:toc-->
- [摘要](#摘要)
- [方法](#方法)
    - [1. "别名-实体"库构建](#1-别名-实体库构建)
        - [生成候选](#生成候选)
        - [统计特征](#统计特征)
    - [2. 概率分](#2-概率分)
    - [3. 相似分](#3-相似分)
<!--END_SECTION:toc-->

<!--

<div align='center'><img src='path/to/xxx.png' height='300'/></div>

<details><summary><b>点击展开</b></summary>
</details>

-->


## 摘要

这篇论文试图解决在搜索查询中高效地进行实体链接的问题。

**关键挑战**
1. **时间约束**：在搜索引擎中，实体链接需要在检索之前完成，通常仅有几毫秒的时间限制。现有系统往往无法满足这种实时性要求。
2. **空间效率**：处理大规模知识库（如维基百科）时，需要高效存储和访问数百万实体及其别名，同时尽量减少内存占用。
3. **上下文利用**：查询通常很短且缺乏上下文，这使得传统基于长文本的实体链接方法效果不佳。如何在有限时间内有效利用上下文信息进行**消歧**是一个难点。
4. **性能与准确性的平衡**：在保证高速处理的同时，还需要维持较高的链接准确性，避免因速度优化而牺牲结果质量。


## 方法

### 1. "别名-实体"库构建

- 核心动作: 把 "**别名**(alias/mention)" 和 "**实体**(entity)" 关联起来;
- 数据来源: 
  1. 带有**锚文本**的知识库(如 Wikipedia); 
  2. 用户的**查询点击**日志;

#### 生成候选
1. 知识库侧
    - 锚文本("Anchor Text"), 示例: `<a href="/wiki/Apple_(Inc.)">apple</a> -> {apple, Apple_(Inc.)}`;
2. 日志侧
    - 存在点击的 `{query, Entity}` 对;

#### 统计特征


符号 | 说明 | 示例
---------|----------|---------
 $s$ | 别名(alias/mention), 可能是**锚文本**或 **Query**; 每个别名可能对应多个实体 | `"apple", "苹果"`
 $e$ | 实体(Entity), 每个实体可能有多个别名 | `"e1:Apple_(Inc.)", "e2:Apple_(fruit)", ...`
 $c_i$ | 数据源, $c_i \in \{c_w,c_q\}$ | $c_w$ - 知识库(如Wikipedia); $c_q$ - 查询日志
 $c_w$ | 数据源-知识库, 通过锚文本关联 $s\rightarrow e$ | `"apple"→"e1:Apple_(Inc.)", ...`
 $c_q$ | 数据源-查询日志, 通过点击关联 $s\rightarrow e$ | `"苹果"→e2:Apple_(fruit), ...`
 $E_i$ | 数据源 $c_i$ 中的全体实体集合 | -
 $Q$ | 用户的搜索 Query | `"taylor swift red lyrics"`
 $S$ | Query 的一种链接方案, 如果片段没有指向实体, 则默认指向 `NOT_LINKED` | `["taylor swift"→"Taylor_Swift_(singer)", "red"→"Red_(Taylor_Swift_album)", "lyrics"→NOT_LINKED]` 
 $a_{s}$ | 指示 $s$ 是否为一个别名, $a_{s}\in \{0,1\}$ | `"apple"`: $a_{s=1}$, `"the"`: $a_{s=0}$
 $a_{e,s}$ | 指示 $s$ 是否为 $e$ 的别名 | `"apple"→"Apple_(Inc.)"`: $a_{e,s=1}$
 $n_{(e, c_w)}$ | 实体 $e$ 在知识库 $c_w$ 中被链接的次数 | `{"Apple_(Inc.)":700, "Apple_(fruit)":300, ...}`
 $n_{(e, c_q)}$ | 实体 $e$ 在查询日志 $c_q$ 中被点击的次数 | `{"Apple_(Inc.)":600, "Apple_(fruit)":100, ...}`
 $n_{(s, c_w)}$ | 别名 $s$ 在知识库 $c_w$ 中作为锚文本的次数(始终有 $a_{s=1}$) | `{"apple":1200}`
 $n_{(s, c_q)}$ | 别名 $s$ 作为 Query 在查询日志 $c_q$ 中的搜索次数, 若存在点击则 $a_{s=1}$, 否则 $a_{s=0}$ | `{"apple":1500}` 
 $n_{(s,c_i,a_{s=1})}$ | 别名 $s$ 在数据源 $c_i$ 中作为别名的次数 | $n_{(s,c_i,a_{s=1})} = \sum\limits_{e_i \in E_i} n_{(s,e_i,c_i)}$ 
 $n_{(s,e,c_i)}$ | 在数据源 $c_i$ 中, $s$ 是 $e$ 别名的次数($a_{e,s=1}$), 即 $n_{(s,e, c_i, a_{e,s=1})}$ | - 


### 2. 概率分

$$P(e|s)$$

**含义**: 给定别名 $s$, 该别名指向实体 $e$ 的概率;
> 现实意义: 超链接 $s$ 或查询 $s$ 指向实体 $e$ 的经验频率, 即
> $$\begin{align*} P(e|s) &= \dfrac{\textrm{s链接到e的次数}+\mu \cdot P(e)}{\textrm{s链接到任意实体的总次数} + \mu} \\ P(e) &= \dfrac{\textrm{e出现的次数} + 1}{\textrm{实体总数} + \textrm{所有实体出现的次数}} \end{align*}$$
>> 上述公式加入了平滑系数

**单数据源**
$$
\begin{align}
P(e|s) 
    &= \underset{=1}{\underbrace{P(c_i|s)}} \cdot P(e|s,c_i) \\
    &= P(a_{s=1}|s,c_i) \cdot P(e|a_{s=1},s,c_i) \\
    &= \dfrac{n_{(s,c_i,a_{s=1})}}{n_{(s,c_i)}} \cdot \dfrac{n_{(s,e,c_i)}}{n_{(s,c_i,a_{s=1})}} \\
    &= \dfrac{n_{(s,e,c_i)}}{n_{(s,c_i)}} \\
    (\textrm{平滑版})&= \dfrac{n_{(s,c_i,a_{s=1})}}{n_{(s,c_i)}} \cdot \dfrac{n_{(s,e,c_i)} + \mu \cdot P(e)}{\mu + n_{(s,c_i,a_{s=1})}}
\end{align}
$$

**多数据源**
$$
\begin{align}
P(e|s) 
    &= \sum\limits_{c_i} P(c_i|s) \cdot P(e|s,c_i) \\
    &= \sum\limits_{c_i} \dfrac {n_{(s,c_i)}} {\sum\limits_{c_i} n_{(s,c_i)}} \cdot P(e|s,c_i) \\
    &= \sum\limits_{c_i} \dfrac {n_{(s,c_i)}} {\sum\limits_{c_i} n_{(s,c_i)}} \cdot P(a_{s=1}|s,c_i) \cdot P(e|a_{s=1},s,c_i) \\
    &= \sum\limits_{c_i} \dfrac {n_{(s,c_i)}} {\sum\limits_{c_i} n_{(s,c_i)}} \cdot \dfrac{n_{(s,c_i,a_{s=1})}}{n_{(s,c_i)}} \cdot \dfrac{n_{(s,e,c_i)}}{n_{(s,c_i,a_{s=1})}} \\
    &= \dfrac {\sum\limits_{c_i} n_{(s,e,c_i)}} {\sum\limits_{c_i} n_{(s,c_i)}} \\
    (\textrm{平滑版})&= \sum\limits_{c_i} \dfrac {n_{(s,c_i)}} {\sum\limits_{c_i} n_{(s,c_i)}} \cdot \dfrac{n_{(s,c_i,a_{s=1})}}{n_{(s,c_i)}} \cdot \dfrac{n_{(s,e,c_i)} + \mu \cdot P(e|c_i)}{\mu + n_{(s,c_i,a_{s=1})}} \\
    &= \sum\limits_{c_i} \dfrac {n_{(s,c_i,a_{s=1})}} {\sum\limits_{c_i} n_{(s,c_i)}} \cdot \dfrac{n_{(s,e,c_i)} + \mu \cdot P(e|c_i)}{\mu + n_{(s,c_i,a_{s=1})}}
\end{align}
$$


**公式说明**

符号 | 说明 | 示例/公式
---------|----------|---------
 $P(T\|Q)$ | $Q$ 的链接结果为 $T$ 的概率, 实体链接的目标即最大化该概率, 一般求其对数形式, 即 $\log P(T\|Q)$ | $\log P(T\|Q) = \sum \log P(e\|s)$
 $P(e\|s)$ | 别名 $s$ 指向实体 $e$ 的概率 | $P(e\|s) = \sum\limits_{c_i\in\{c_w,c_q\}}P(c_i\|s) \cdot P(e\|s,c_i)$ 
 $P(c_i\|s)$ | 别名 $s$ 来自数据源 $c_i$ 的概率, $c_i\in\{c_w,c_q\}$ | $\begin{aligned} P(c_i\|s) &= \dfrac {n_{(s,c_i)}} {\sum\limits_{c_i} n_{(s,c_i)}} \\ \sum\limits_{c_i} P(c_i\|s) &= 1, c_i \in \{c_w, c_q\} \end{aligned}$ 
 $P(e\|s,c_i)$ | 在数据源 $c_i$ 中, $s$ 指向 $e$ 的概率, $c_i\in\{c_w,c_q\}$ | $\begin{aligned} P(e\|s,c_i) &= \sum\limits_{a_s\in \{0,1\}} P(a_{s}\|s,c_i)\cdot P(e\|a_{s},s,c_i) \\ &= P(a_{s=1}\|s,c_i)\cdot P(e\|a_{s=1},s,c_i) + P(a_{s=0}\|s,c_i)\cdot \underset{=0}{\underbrace{P(e\|a_{s=0},s,c_i)}} \\ &= P(a_{s=1}\|s,c_i)\cdot P(e\|a_{s=1},s,c_i) \end{aligned}$ 
 $P(a_{s=1}\|s,c_i)$ | 在数据源 $c_i$ 中, 别名 $s$ 有效的概率(被锚定或被点击) | $P(a_{s=1}\|s,c_i) = \dfrac{\sum\limits_{e_i} n_{(s,e_i,c_i)}}{n_{(s,c_i)}}$ 
 $P(e\|a_{s=1},s,c_i)$ | 在数据源 $c_i$ 中, 别名 $s$ 指向实体 $e$ 的概率(平滑版) | $P(e\|a_{s=1},s,c_i) = \dfrac{n_{(s,e,c_i)} + \mu \cdot P(e\|c_i)}{\mu + \sum\limits_{e_i} n_{(s,e_i,c_i)}}$ 
 $P(e\|c_i)$ | 实体的先验概率, 即实体 $e$ 在数据源中全局频率 | $\begin{aligned} P(e\|c_i) &= \dfrac{1 + n_{(e,c_i)}}{\sum\limits_{e\in E_i} \left (1 + n_{(e,c_i)} \right )}, \textrm{(平滑版)} \\ &= \dfrac{1 + n_{(e,c_i)}}{\|E_i\| + \sum\limits_{e\in E_i} n_{(e,c_i)}} \end{aligned}$

<!-- 
#### 先验平滑

**目的**
1. 防止零概率;
2. 缓解数据稀疏性, 平衡观测数据与先验知识之间的关系;
 -->

### 3. 相似分

$$P(e|\textrm{Context})$$

**含义**: 实体与上下文的语义相似度;
> 论文使用 Word2Vec 计算实体与查询词的词向量;

**最终得分**:

$$P'(e|s) = P(e|s) \cdot P(e|\textrm{Context})$$