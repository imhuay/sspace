大模型微调面试问题整理
===
<!--START_SECTION:badge-->
![create date](https://img.shields.io/static/v1?label=create%20date&message=2025-09-13&label_color=gray&color=lightsteelblue&style=flat-square)
![last modify](https://img.shields.io/static/v1?label=last%20modify&message=2025-09-15%2004%3A00%3A25&label_color=gray&color=thistle&style=flat-square)
<!--END_SECTION:badge-->
<!--info
date: 2025-09-13 16:23:17
toc_title: 面试问题整理
top: false
draft: false
hidden: true
section_number: true
level: -1
tag: [llm]
-->

<!--START_SECTION:keywords-->
> ***Keywords**: 大模型微调面试问题整理*
<!--END_SECTION:keywords-->

<!--START_SECTION:paper_title-->
<!--END_SECTION:paper_title-->

<!--START_SECTION:toc-->
- [1. 🏷️ **基础概念**](#1-️-基础概念)
    - [1.1. ✅ 解释一下什么是 **大模型微调**?](#11--解释一下什么是-大模型微调)
        - [1.1.1. ☑️ 为什么需要 **微调**?](#111-️-为什么需要-微调)
        - [1.1.2. ☑️ **微调** 与 **预训练** 的区别](#112-️-微调-与-预训练-的区别)
    - [1.2. ✅ 说明 **大模型微调的一般流程**](#12--说明-大模型微调的一般流程)
    - [1.3. ✅ 比较 **全量微调** 和 **参数高效微调 (PEFT)**](#13--比较-全量微调-和-参数高效微调-peft)
        - [1.3.1. ✅ 什么是 **灾难性遗忘**? 如何缓解?](#131--什么是-灾难性遗忘-如何缓解)
- [2. 🏷️ **参数高效微调 (PEFT, Parameter-Efficient Fine-Tuning)**](#2-️-参数高效微调-peft-parameter-efficient-fine-tuning)
    - [2.1. ✅ 介绍常见的 **PEFT** 技术](#21--介绍常见的-peft-技术)
    - [2.2. 🔥 **LoRA (Low-Rank Adaptation)**](#22--lora-low-rank-adaptation)
        - [2.2.1. ✅ 什么是 LoRA？它解决了什么问题？适用什么 **场景**?](#221--什么是-lora它解决了什么问题适用什么-场景)
        - [2.2.2. ✅ 与全参微调相比, LoRA 的 **表达上限** 如何？](#222--与全参微调相比-lora-的-表达上限-如何)
        - [2.2.3. ✅ LoRA 的参数量如何计算？与原参数量的比例？](#223--lora-的参数量如何计算与原参数量的比例)
        - [2.2.4. ✅ LoRA 一般作用于哪些层?](#224--lora-一般作用于哪些层)
        - [2.2.5. 💡 写出 LoRA 的 **数学形式**，并解释各参数的含义与约束](#225--写出-lora-的-数学形式并解释各参数的含义与约束)
            - [2.2.5.1. ✅ 为何需要 **缩放项** `α/r`？去掉会怎样？](#2251--为何需要-缩放项-αr去掉会怎样)
            - [2.2.5.2. ✅ 为什么常将 `A` 正态初始化, `B` 初始化为 `0`? 如果不这么做会怎么样?](#2252--为什么常将-a-正态初始化-b-初始化为-0-如果不这么做会怎么样)
            - [✅ 如何选择 `r` (Rank)？不同任务/数据规模下的建议是什么？](#-如何选择-r-rank不同任务数据规模下的建议是什么)
            - [💡 如果希望逼近全参微调效果，除了增大 r 还能做什么？](#-如果希望逼近全参微调效果除了增大-r-还能做什么)
        - [🔖 LoRA 的变体与对比](#-lora-的变体与对比)
            - [](#)
<!--END_SECTION:toc-->

---

## 1. 🏷️ **基础概念**

### 1.1. ✅ 解释一下什么是 **大模型微调**?
> - 大模型微调是利用 **特定数据** 对 **通用预训练模型** 进行 **再训练**, 以高效地让其 **适配下游任务** 的关键技术;

#### 1.1.1. ☑️ 为什么需要 **微调**?
> - 高适配, 低成本, 高效率

#### 1.1.2. ☑️ **微调** 与 **预训练** 的区别
> - 训练目标不同, 数据规模不同, 训练成本不同, 模型能力侧重不同

<details><summary><b>详述</b></summary>

| 维度 | 预训练 | 微调 |
| --- | --- | --- |
| 训练目标不同 | 学习通用语言模式与知识表示, 构建广泛的基础能力 | 适配特定任务或领域, 提升在该场景下的性能 |
| 数据规模不同 | 使用大规模、跨领域的通用数据集 | 使用较小规模、领域相关或任务特定的数据集 |
| 训练成本不同 | 需要极高的计算资源与时间成本 | 在已有模型基础上进行, 成本显著降低 |
| 模型能力侧重不同 | 获得广泛的通用能力 | 强化特定任务能力, 可能牺牲部分通用性 |

</details>

### 1.2. ✅ 说明 **大模型微调的一般流程**
> 1. **需求分析**: 确定 **输入输出** 形式, 评价指标;
> 2. **数据准备/预处理**: 收集高质量数据, 清洗, 去噪, 格式化; 数据集划分;
> 3. **模型选择**: 考虑因素包括 **模型能力** (通用/领域), **参数量** 和 **计算资源**;
> 4. **微调策略**: 全参数微调 / 参数高效微调 (LoRA 等方法); 偏好学习 (RL)
> 5. **训练与监控**: 训练环境, 超参数 (学习率、批大小、优化器), 验证集指标变化;
> 6. **模型评估**: 测试集性能评估 (过拟合/欠拟合), case 分析;
> 7. **部署与持续优化**: 模型部署; 收集反馈数据, 增量微调/再训练;

<details><summary><b>备注</b></summary>

- 大模型把所有任务统一到了 **生成任务**, 因此确定 **输入输出形式** 比 **任务类型** 更重要;

</details>

### 1.3. ✅ 比较 **全量微调** 和 **参数高效微调 (PEFT)**
> - 参数更新范围, 资源成本/训练速度, 数据需求, 灾难性遗忘, 适用场景
> - **总结**: 全量微调追求极致性能但成本高, PEFT 以低成本实现高适配性并保留通用能力 (减轻灾难性遗忘);

<details><summary><b>详述</b></summary>

| 对比维度 | 全量微调 | 参数高效微调 (PEFT) |
|---|---|---|
| **参数更新范围** | **全部参数** | **少量新增或选定的参数** |
| **资源成本/训练速度** | 计算量与显存占用**高**, **训练慢** | 计算量与显存占用**低**, **训练快** |
| **数据需求** | 需要**大规模数据**以避免过拟合 | 对数据量要求相对较低 |
| **灾难性遗忘** | **严重** | **较轻** |
| **适用场景** | **资源充足**, 追求极致性能 | **资源有限**, 多任务部署或快速迭代 |

</details>

#### 1.3.1. ✅ 什么是 **灾难性遗忘**? 如何缓解?
> - **含义**: 模型在新数据上学习时, 覆盖了之前学到的知识;  
> - **缓解方法**: 混合训练数据, 更小的学习率, 正则化约束, 参数隔离, 渐进式微调


## 2. 🏷️ **参数高效微调 (PEFT, Parameter-Efficient Fine-Tuning)**

### 2.1. ✅ 介绍常见的 **PEFT** 技术
> LoRA/QLoRA, Adapter, Prompt/Prefix Tuning, P-Tuning V1/V2, BitFit

<details><summary><b>简述与代码示例</b></summary>



</details>

### 2.2. 🔥 **LoRA (Low-Rank Adaptation)**
> [LoRA](./LoRA.md)

#### 2.2.1. ✅ 什么是 LoRA？它解决了什么问题？适用什么 **场景**?
> - **LoRA** 是一种当前非常流行的 **参数高效微调 (PEFT)** 技术;  
> - **优势/解决的问题**: 全参数微调成本高, 多任务存储冗余, 部署灵活性不足, 减少灾难性遗忘;
> - **适用场景**: 资源受限, 快速迭代, 多任务部署, 避免灾难性遗忘;

#### 2.2.2. ✅ 与全参微调相比, LoRA 的 **表达上限** 如何？
> - **表达上限**: LoRA 的权重更新被约束在了一个 **低秩子空间** 内, 其复杂性受限于 **秩 ($r$)** 的大小; 
> - 对于 **与预训练分布差异大** 的任务, 表达上限可能会低于全参微调;
> - 从数学角度看, 当 $r$ 设置的足够大时, 模型完全有可能在新任务上重塑特征空间 (虽然这与 LoRA 设计的初衷不符);

#### 2.2.3. ✅ LoRA 的参数量如何计算？与原参数量的比例？
> - **LoRA 的参数量**: $r(d_{in}+d_{out})$
> - **参数比**: $\dfrac{r(d_{in}+d_{out})}{d_{in} \times d_{out}}$; 通常能压缩到百分之一到千分之一的量级;

#### 2.2.4. ✅ LoRA 一般作用于哪些层?
> - 大部分线性层 `nn.Linear`: 
>   - 注意力层中的 $W_q, W_k, W_v, W_o$
>   - MLP 层中的 $W_{up}, W_{down}, W_{gate}$

#### 2.2.5. 💡 写出 LoRA 的 **数学形式**，并解释各参数的含义与约束
> $h = Wx + \dfrac{\alpha}{r}B(Ax)$
>> [LoRA](./LoRA.md#基础概念)

##### 2.2.5.1. ✅ 为何需要 **缩放项** `α/r`？去掉会怎样？
> - **作用**: 稳定训练并控制更新幅度; 去掉会让更新量随秩变化而失控, 增加训练不稳定与调参难度;

##### 2.2.5.2. ✅ 为什么常将 `A` 正态初始化, `B` 初始化为 `0`? 如果不这么做会怎么样?
> - **`A` 正态初始化**: 保证了各方向的更新潜力均衡, 避免某些方向先天缺乏梯度信号;
> - **`B` 初始化为 `0`**: 在 **训练开始** 时保持与原模型一致, 确保模型从 **安全可控** 的状态开始学习;
> - 不这么做: **梯度爆炸**, **训练震荡**, **收敛困难**, **灾难性遗忘**;

##### ✅ 如何选择 `r` (Rank)？不同任务/数据规模下的建议是什么？
> - 简单任务/小数据从 r=4/8 开始，中等任务从 r=16/32 开始，复杂任务/大数据可尝试 r=64/128，并配合缩放项与验证集监控动态调整;

##### 💡 如果希望逼近全参微调效果，除了增大 r 还能做什么？
> - [改进 LoRA 结构](./LoRA.md#结构改进); **多位置接入** (MLP 层); **逐步解冻**/**混合训练**; **超参优化**(学习率/eopch 等); 更先进的算法 (DoRA 等);

#### 🔖 LoRA 的变体与对比

##### 

---

<details><summary><b>参考资料</b></summary>

<!-- omit in toc -->
<!-- ## 📍 参考资料 -->
- [大模型微调模拟面试 - DeepSeek](https://chat.deepseek.com/a/chat/s/7342a1fe-2d3f-487f-aa41-bec5af706268)
- [大模型微调模拟面试 - Copilot](https://copilot.microsoft.com/chats/BmUFVXkQA5qt96LBUEpJK)

</details>
