大模型微调面试问题整理
===
<!--START_SECTION:badge-->
![create date](https://img.shields.io/static/v1?label=create%20date&message=2025-09-13&label_color=gray&color=lightsteelblue&style=flat-square)
![last modify](https://img.shields.io/static/v1?label=last%20modify&message=2025-09-14%2012%3A57%3A42&label_color=gray&color=thistle&style=flat-square)
<!--END_SECTION:badge-->
<!--info
date: 2025-09-13 16:23:17
toc_title: 面试问题整理
top: false
draft: false
hidden: true
section_number: false
level: 0
tag: []
-->

<!--START_SECTION:keywords-->
> ***Keywords**: 大模型微调面试问题整理*
<!--END_SECTION:keywords-->

<!--START_SECTION:paper_title-->
<!--END_SECTION:paper_title-->

<!--START_SECTION:toc-->
- [1. 🏷️ 基础概念](#1-️-基础概念)
    - [1.1. ✅ 解释一下什么是 **大模型微调**?](#11--解释一下什么是-大模型微调)
        - [1.1.1. ☑️ 为什么需要 **微调**?](#111-️-为什么需要-微调)
        - [1.1.2. ☑️ **微调** 与 **预训练** 的区别](#112-️-微调-与-预训练-的区别)
    - [1.2. ✅ 说明 **大模型微调的一般流程**](#12--说明-大模型微调的一般流程)
    - [1.3. ✅ 比较 **全量微调** 和 **参数高效微调 (PEFT)**](#13--比较-全量微调-和-参数高效微调-peft)
        - [1.3.1. ✅ 什么是 **灾难性遗忘**? 如何缓解?](#131--什么是-灾难性遗忘-如何缓解)
- [2. 🏷️ **参数高效微调 (PEFT)**](#2-️-参数高效微调-peft)
    - [2.1. ✅ 介绍常见的 **PEFT** 技术](#21--介绍常见的-peft-技术)
    - [🔥 详细介绍 **LoRA**](#-详细介绍-lora)
<!--END_SECTION:toc-->

---

## 1. 🏷️ 基础概念

### 1.1. ✅ 解释一下什么是 **大模型微调**?
> - 大模型微调是利用 **特定数据** 对 **通用预训练模型** 进行 **再训练**, 以高效地让其 **适配下游任务** 的关键技术;

#### 1.1.1. ☑️ 为什么需要 **微调**?
> - 高适配, 低成本, 高效率

#### 1.1.2. ☑️ **微调** 与 **预训练** 的区别
> - 训练目标不同, 数据规模不同, 训练成本不同, 模型能力侧重不同

<details><summary><b>详述</b></summary>

| 维度 | 预训练 | 微调 |
| --- | --- | --- |
| 训练目标不同 | 学习通用语言模式与知识表示, 构建广泛的基础能力 | 适配特定任务或领域, 提升在该场景下的性能 |
| 数据规模不同 | 使用大规模、跨领域的通用数据集 | 使用较小规模、领域相关或任务特定的数据集 |
| 训练成本不同 | 需要极高的计算资源与时间成本 | 在已有模型基础上进行, 成本显著降低 |
| 模型能力侧重不同 | 获得广泛的通用能力 | 强化特定任务能力, 可能牺牲部分通用性 |

</details>

### 1.2. ✅ 说明 **大模型微调的一般流程**
> 1. **需求分析**: 确定 **输入输出** 形式, 评价指标;
> 2. **数据准备/预处理**: 收集高质量数据, 清洗, 去噪, 格式化; 数据集划分;
> 3. **模型选择**: 考虑因素包括 **模型能力** (通用/领域), **参数量** 和 **计算资源**;
> 4. **微调策略**: 全参数微调 / 参数高效微调 (LoRA 等方法); 偏好学习 (RL)
> 5. **训练与监控**: 训练环境, 超参数 (学习率、批大小、优化器), 验证集指标变化;
> 6. **模型评估**: 测试集性能评估 (过拟合/欠拟合), case 分析;
> 7. **部署与持续优化**: 模型部署; 收集反馈数据, 增量微调/再训练;

<details><summary><b>备注</b></summary>

- 大模型把所有任务统一到了 **生成任务**, 因此确定 **输入输出形式** 比 **任务类型** 更重要;

</details>

### 1.3. ✅ 比较 **全量微调** 和 **参数高效微调 (PEFT)**
> - 参数更新范围, 资源成本/训练速度, 数据需求, 灾难性遗忘, 适用场景
> - **总结**: 全量微调追求极致性能但成本高, PEFT 以低成本实现高适配性并保留通用能力 (减轻灾难性遗忘);

<details><summary><b>详述</b></summary>

| 对比维度 | 全量微调 | 参数高效微调 (PEFT) |
|---|---|---|
| **参数更新范围** | **全部参数** | **少量新增或选定的参数** |
| **资源成本/训练速度** | 计算量与显存占用**高**, **训练慢** | 计算量与显存占用**低**, **训练快** |
| **数据需求** | 需要**大规模数据**以避免过拟合 | 对数据量要求相对较低 |
| **灾难性遗忘** | **严重** | **较轻** |
| **适用场景** | **资源充足**, 追求极致性能 | **资源有限**, 多任务部署或快速迭代 |

</details>

#### 1.3.1. ✅ 什么是 **灾难性遗忘**? 如何缓解?
> - **含义**: 模型在新数据上学习时, 覆盖了之前学到的知识;  
> - **缓解方法**: 混合训练数据, 更小的学习率, 正则化约束, 参数隔离, 渐进式微调


## 2. 🏷️ **参数高效微调 (PEFT)**

### 2.1. ✅ 介绍常见的 **PEFT** 技术
> LoRA/QLoRA, Adapter, Prompt/Prefix Tuning, P-Tuning V1/V2

<details><summary><b>简述与代码示例</b></summary>

- **LoRA/QLoRA**:
    - **思路**:
        - 冻结原模型权重, 在需要微调的 **线性层** 旁边 **加** 一个 **低秩旁路矩阵** $\Delta W = A B$, 只训练这个旁路矩阵分解后的参数 $A, B$;
            - 其中 $\Delta W \in R^{dxk}$, $A \in R^{dxr}$, $B \in R^{rxk}$,
            - 且 $r << d,k$, 这就是 **低秩** 的含义, 这样做是基于 **内在维度** 的假设;
            - 旁路操作类似 **残差**;
        - **QLoRA** 在 LoRA 基础上加了 **权重量化**, 显存占用更低;
    - **代码 Demo**:
        - [LoRa](./code/lora.py)
- **Adapter**:
    - **思路**:
        - 在 Transformer 每层的前馈网络 (或注意力输出) 后插入一个小型可训练的 **瓶颈层** (bottleneck)
    - **代码 Demo**
        - [Adapter](./code/adapter.py)
- **Prompt/Prefix Tuning** (**参数注入位置** 不同):
    - **思路**:
        - Prompt Tuning 仅在 **输入嵌入层** 前拼接可训练的软提示向量;
        - Prefix Tuning 在 **Transformer 每一层的注意力机制** 中, 为 Key/Value 拼接可训练的 **前缀向量**;
    - **代码 Demo**
        - [Prefix Tuning](./code/prefix_tuning.py)
        - [Prompt Tuning](./code/prompt_tuning.py)
- **P-Tuning V1/V2**
    - **思路**:
        - 将原本人工设计的离散 Prompt 替换为可训练的连续向量 (virtual tokens);
        - 这些向量通过一个提示编码器 (Prompt Encoder)  (通常是 LSTM + MLP) 生成;
        - V1/V2 的区别类似 Prefix/Prompt Tuning, **仅作用于输入层 vs 作用于每一个 TransformerBlock**;
    - **代码 Demo**
        - [P-Tuning V1](./code/p_tuning.py)
        - [P-Tuning V2](./code/p_tuning_v2.py)

</details>

### 🔥 详细介绍 **LoRA**


---

<details><summary><b>参考资料</b></summary>

<!-- omit in toc -->
<!-- ## 📍 参考资料 -->
- [大模型微调模拟面试 - DeepSeek](https://chat.deepseek.com/a/chat/s/7342a1fe-2d3f-487f-aa41-bec5af706268)
- [大模型微调模拟面试 - Copilot](https://copilot.microsoft.com/chats/BmUFVXkQA5qt96LBUEpJK)

</details>



