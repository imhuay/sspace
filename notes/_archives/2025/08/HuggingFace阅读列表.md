HuggingFace (博客 & 代码)
===
<!--START_SECTION:badge-->

![last modify](https://img.shields.io/static/v1?label=last%20modify&message=2025-08-17%2005%3A14%3A41&color=yellowgreen&style=flat-square)

<!--END_SECTION:badge-->
<!--info
date: 2025-08-17 04:47:17
top: false
draft: false
hidden: true
level: 0
tag: [read]
-->

> ***Keywords**: 阅读列表*

<!--START_SECTION:paper_title-->
<!--END_SECTION:paper_title-->

<!--START_SECTION:toc-->
- [博客](#博客)
- [代码](#代码)
<!--END_SECTION:toc-->

---

## 博客
> [Hugging Face – 博客](https://huggingface.co/blog/zh)

- [ ] [[2024-11-25] 设计位置编码](https://huggingface.co/blog/zh/designing-positional-encoding)
    > [笔记 | Transformer位置编码](./Transformer位置编码.md)
- [ ] [[2024-06-13] 从 DeepSpeed 到 FSDP，再回到 Hugging Face Accelerate](https://huggingface.co/blog/zh/deepspeed-to-fsdp-and-back)
- [ ] [[2024-05-28] 用 Sentence Transformers v3 训练和微调嵌入模型](https://huggingface.co/blog/zh/train-sentence-transformers)
- [ ] [[2024-02-23] 使用 Hugging Face 微调 Gemma 模型](https://huggingface.co/blog/zh/gemma-peft)
- [ ] [[2024-01-02] 全世界 LoRA 训练脚本，联合起来!](https://huggingface.co/blog/zh/sdxl_lora_advanced_script)
- [ ] [[2023-12-11] 混合专家模型（MoE）详解](https://huggingface.co/blog/zh/moe)
- [ ] [[2023-10-24] 使用 PPO 算法进行 RLHF 的 N 步实现细节](https://huggingface.co/blog/zh/the_n_implementation_details_of_rlhf_with_ppo)
- [ ] [[2023-09-29] 使用 DDPO 在 TRL 中微调 Stable Diffusion 模型](https://huggingface.co/blog/zh/trl-ddpo)
- [ ] [[2023-09-13] 使用 PyTorch FSDP 微调 Llama 2 70B](https://huggingface.co/blog/zh/ram-efficient-pytorch-fsdp)
- [ ] [[2023-08-08] 使用 DPO 微调 Llama 2](https://huggingface.co/blog/zh/dpo-trl)
- [ ] [[2023-06-12] 基础大模型能像人类一样标注数据吗？](https://huggingface.co/blog/zh/open-llm-leaderboard-rlhf)
- [ ] [[2023-03-09] 在一张 24 GB 的消费级显卡上用 RLHF 微调 20B LLMs](https://huggingface.co/blog/zh/trl-peft)
- [ ] [[2023-02-03] 深入了解视觉语言模型](https://huggingface.co/blog/zh/vision_language_pretraining)
- [ ] [[2023-01-26] 使用 LoRA 进行 Stable Diffusion 的高效参数微调](https://huggingface.co/blog/zh/lora)
- [ ] [[2023-01-24] 是什么让对话代理有用？](https://huggingface.co/blog/zh/dialog-agents)
- [ ] [[2023-01-03] 一文带你入门图机器学习](https://huggingface.co/blog/zh/intro-graphml)
- [ ] [[2022-12-09] ChatGPT 背后的“功臣”——RLHF 技术详解](https://huggingface.co/blog/zh/rlhf)
- [ ] [[2022-12-01] 使用 🤗 Transformers 进行概率时间序列预测](https://huggingface.co/blog/zh/time-series-transformers)
- [ ] [[2022-11-08] 在 Transformers 中使用对比搜索生成可媲美人类水平的文本🤗](https://huggingface.co/blog/zh/introducing-csearch)
- [ ] [[2022-10-21] 从 PyTorch DDP 到 Accelerate 到 Trainer，轻松掌握分布式训练](https://huggingface.co/blog/zh/pytorch-ddp-accelerate-transformers)
- [ ] [[2022-09-07] 如何使用 Megatron-LM 训练语言模型](https://huggingface.co/blog/zh/megatron-training)
- [ ] [[2022-05-02] 使用 PyTorch 完全分片数据并行技术加速大模型训练](https://huggingface.co/blog/zh/pytorch-fsdp)
- [ ] [[2022-04-05] 〜不要〜重复自己](https://huggingface.co/blog/zh/transformers-design-philosophy)
- [ ] [[2021-03-09] 长程 transformer 模型](https://huggingface.co/blog/zh/long-range-transformers)
- [ ] [[2021-01-18] 如何成功将 🤗 API 客户的 transformer 模型推理速度加快 100 倍](https://huggingface.co/blog/zh/accelerated-inference)
- [ ] [[2020-10-10] 基于 Transformers 的编码器-解码器模型](https://huggingface.co/blog/zh/encoder-decoder)
- [ ] [[2020-07-03] Reformer 模型 - 突破语言建模的极限](https://huggingface.co/blog/zh/reformer)
- [ ] [[2020-03-01] 如何生成文本：通过 Transformers 用不同的解码方法生成文本](https://huggingface.co/blog/zh/how-to-generate)


## 代码

- [ ] [GRPO Trainer](https://huggingface.co/docs/trl/v0.16.1/en/grpo_trainer)